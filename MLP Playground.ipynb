{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0   65  Female              0.7               0.1                   187   \n",
       "1   62    Male             10.9               5.5                   699   \n",
       "2   62    Male              7.3               4.1                   490   \n",
       "3   58    Male              1.0               0.4                   182   \n",
       "4   72    Male              3.9               2.0                   195   \n",
       "\n",
       "   Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                        16                          18             6.8   \n",
       "1                        64                         100             7.5   \n",
       "2                        60                          68             7.0   \n",
       "3                        14                          20             6.8   \n",
       "4                        27                          59             7.3   \n",
       "\n",
       "   Albumin  Albumin_and_Globulin_Ratio  Dataset  \n",
       "0      3.3                        0.90        1  \n",
       "1      3.2                        0.74        1  \n",
       "2      3.3                        0.89        1  \n",
       "3      3.4                        1.00        1  \n",
       "4      2.4                        0.40        1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"datasets_2607_4342_indian_liver_patient_labelled.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>98</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>52</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>245</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>184</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>38</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>216</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0     65  Female              0.7               0.1                   187   \n",
       "1     62    Male             10.9               5.5                   699   \n",
       "2     62    Male              7.3               4.1                   490   \n",
       "3     58    Male              1.0               0.4                   182   \n",
       "4     72    Male              3.9               2.0                   195   \n",
       "..   ...     ...              ...               ...                   ...   \n",
       "578   60    Male              0.5               0.1                   500   \n",
       "579   40    Male              0.6               0.1                    98   \n",
       "580   52    Male              0.8               0.2                   245   \n",
       "581   31    Male              1.3               0.5                   184   \n",
       "582   38    Male              1.0               0.3                   216   \n",
       "\n",
       "     Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                          16                          18             6.8   \n",
       "1                          64                         100             7.5   \n",
       "2                          60                          68             7.0   \n",
       "3                          14                          20             6.8   \n",
       "4                          27                          59             7.3   \n",
       "..                        ...                         ...             ...   \n",
       "578                        20                          34             5.9   \n",
       "579                        35                          31             6.0   \n",
       "580                        48                          49             6.4   \n",
       "581                        29                          32             6.8   \n",
       "582                        21                          24             7.3   \n",
       "\n",
       "     Albumin  Albumin_and_Globulin_Ratio  Dataset  \n",
       "0        3.3                        0.90        1  \n",
       "1        3.2                        0.74        1  \n",
       "2        3.3                        0.89        1  \n",
       "3        3.4                        1.00        1  \n",
       "4        2.4                        0.40        1  \n",
       "..       ...                         ...      ...  \n",
       "578      1.6                        0.37        2  \n",
       "579      3.2                        1.10        1  \n",
       "580      3.2                        1.00        1  \n",
       "581      3.4                        1.00        1  \n",
       "582      4.4                        1.50        2  \n",
       "\n",
       "[583 rows x 11 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col] = df[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'Gender',\n",
       " 'Total_Bilirubin',\n",
       " 'Direct_Bilirubin',\n",
       " 'Alkaline_Phosphotase',\n",
       " 'Alamine_Aminotransferase',\n",
       " 'Aspartate_Aminotransferase',\n",
       " 'Total_Protiens',\n",
       " 'Albumin',\n",
       " 'Albumin_and_Globulin_Ratio']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = list(df.columns)\n",
    "headers.remove('Dataset')\n",
    "# headers.remove('Gender')\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.get_dummies(df['Gender'], prefix='Gender')\n",
    "df = pd.concat([df, pd.get_dummies(data['Gender'], prefix='Gender')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers.remove('Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[headers]\n",
    "Y = df['Dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Dataset'] = df['Dataset'].replace([1], 0)\n",
    "df['Dataset'] = df['Dataset'].replace([2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(2,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=2000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=1, shuffle=True, solver='lbfgs',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2,), random_state=1, max_iter=2000)\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is 0.48087934621317957\n",
      "Mean accuracy is 0.7307032590051458\n"
     ]
    }
   ],
   "source": [
    "print(\"The loss is\", clf.loss_)\n",
    "print(\"Mean accuracy is\", clf.score(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_dict = {}\n",
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "activation_functions = ['identity', 'logistic', 'tanh', 'relu']\n",
    "hidden_layer_sizes = [(2,), (3,), (5,), (2,2,), (3,2,), (5,2,)]\n",
    "# learning_rates = ['constant', 'invscaling', 'adaptive'] # only for sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "for solver in solvers:\n",
    "    for ac in activation_functions:\n",
    "        for hidden_layer_config in hidden_layer_sizes:\n",
    "            clf = MLPClassifier(solver=solver, alpha=1e-5, hidden_layer_sizes=hidden_layer_config, random_state=1, max_iter=5000, activation=ac)\n",
    "            clf.fit(X, Y)\n",
    "            comparison_dict[count] = {\"solver\":solver, \"activation_function\": ac, \"hidden_layers\":hidden_layer_config, \"accuracy\": clf.score(X,Y), \"loss\":clf.loss_}\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'solver': 'lbfgs',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (2,),\n",
       "  'accuracy': 0.7358490566037735,\n",
       "  'loss': 0.4925446421144629},\n",
       " 2: {'solver': 'lbfgs',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (3,),\n",
       "  'accuracy': 0.7358490566037735,\n",
       "  'loss': 0.49254177629683094},\n",
       " 3: {'solver': 'lbfgs',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (5,),\n",
       "  'accuracy': 0.7358490566037735,\n",
       "  'loss': 0.4925432406995813},\n",
       " 4: {'solver': 'lbfgs',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (2, 2),\n",
       "  'accuracy': 0.7358490566037735,\n",
       "  'loss': 0.4925421228679915},\n",
       " 5: {'solver': 'lbfgs',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (3, 2),\n",
       "  'accuracy': 0.7358490566037735,\n",
       "  'loss': 0.4925422387424394},\n",
       " 6: {'solver': 'lbfgs',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (5, 2),\n",
       "  'accuracy': 0.7358490566037735,\n",
       "  'loss': 0.4925457291509179},\n",
       " 7: {'solver': 'lbfgs',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (2,),\n",
       "  'accuracy': 0.7564322469982847,\n",
       "  'loss': 0.45542545464956263},\n",
       " 8: {'solver': 'lbfgs',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (3,),\n",
       "  'accuracy': 0.7632933104631218,\n",
       "  'loss': 0.44217941646426623},\n",
       " 9: {'solver': 'lbfgs',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (5,),\n",
       "  'accuracy': 0.7993138936535163,\n",
       "  'loss': 0.3931883988551013},\n",
       " 10: {'solver': 'lbfgs',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (2, 2),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.47398146594891133},\n",
       " 11: {'solver': 'lbfgs',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (3, 2),\n",
       "  'accuracy': 0.7564322469982847,\n",
       "  'loss': 0.4316269182581989},\n",
       " 12: {'solver': 'lbfgs',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (5, 2),\n",
       "  'accuracy': 0.7598627787307033,\n",
       "  'loss': 0.41039795613577934},\n",
       " 13: {'solver': 'lbfgs',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (2,),\n",
       "  'accuracy': 0.7547169811320755,\n",
       "  'loss': 0.4616859271581206},\n",
       " 14: {'solver': 'lbfgs',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (3,),\n",
       "  'accuracy': 0.7392795883361921,\n",
       "  'loss': 0.4297708152328627},\n",
       " 15: {'solver': 'lbfgs',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (5,),\n",
       "  'accuracy': 0.7890222984562607,\n",
       "  'loss': 0.3881957789348716},\n",
       " 16: {'solver': 'lbfgs',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (2, 2),\n",
       "  'accuracy': 0.7461406518010292,\n",
       "  'loss': 0.4432338167655391},\n",
       " 17: {'solver': 'lbfgs',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (3, 2),\n",
       "  'accuracy': 0.7307032590051458,\n",
       "  'loss': 0.418625654511915},\n",
       " 18: {'solver': 'lbfgs',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (5, 2),\n",
       "  'accuracy': 0.8181818181818182,\n",
       "  'loss': 0.35891763430634405},\n",
       " 19: {'solver': 'lbfgs',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (2,),\n",
       "  'accuracy': 0.7307032590051458,\n",
       "  'loss': 0.48087934621317957},\n",
       " 20: {'solver': 'lbfgs',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (3,),\n",
       "  'accuracy': 0.725557461406518,\n",
       "  'loss': 0.480357175589928},\n",
       " 21: {'solver': 'lbfgs',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (5,),\n",
       "  'accuracy': 0.7650085763293311,\n",
       "  'loss': 0.42500793816147686},\n",
       " 22: {'solver': 'lbfgs',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (2, 2),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.4841770331271481},\n",
       " 23: {'solver': 'lbfgs',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (3, 2),\n",
       "  'accuracy': 0.7289879931389366,\n",
       "  'loss': 0.45894594898288116},\n",
       " 24: {'solver': 'lbfgs',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (5, 2),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.42725337300265964},\n",
       " 25: {'solver': 'sgd',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (2,),\n",
       "  'accuracy': 0.7101200686106347,\n",
       "  'loss': 0.5160301857644858},\n",
       " 26: {'solver': 'sgd',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (3,),\n",
       "  'accuracy': 0.725557461406518,\n",
       "  'loss': 0.5169866275000312},\n",
       " 27: {'solver': 'sgd',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (5,),\n",
       "  'accuracy': 0.725557461406518,\n",
       "  'loss': 0.5145220214835178},\n",
       " 28: {'solver': 'sgd',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (2, 2),\n",
       "  'accuracy': 0.7238421955403087,\n",
       "  'loss': 0.5111677189137138},\n",
       " 29: {'solver': 'sgd',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (3, 2),\n",
       "  'accuracy': 0.7341337907375644,\n",
       "  'loss': 0.49961346786918587},\n",
       " 30: {'solver': 'sgd',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (5, 2),\n",
       "  'accuracy': 0.7204116638078902,\n",
       "  'loss': 0.5183680336002336},\n",
       " 31: {'solver': 'sgd',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (2,),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.5922861998718005},\n",
       " 32: {'solver': 'sgd',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (3,),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.6048642669502357},\n",
       " 33: {'solver': 'sgd',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (5,),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.6062615038154975},\n",
       " 34: {'solver': 'sgd',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (2, 2),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.602656366323258},\n",
       " 35: {'solver': 'sgd',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (3, 2),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.6007139322100902},\n",
       " 36: {'solver': 'sgd',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (5, 2),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.6032752780612447},\n",
       " 37: {'solver': 'sgd',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (2,),\n",
       "  'accuracy': 0.7204116638078902,\n",
       "  'loss': 0.5208315216819885},\n",
       " 38: {'solver': 'sgd',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (3,),\n",
       "  'accuracy': 0.7152658662092625,\n",
       "  'loss': 0.5342900358601599},\n",
       " 39: {'solver': 'sgd',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (5,),\n",
       "  'accuracy': 0.7186963979416809,\n",
       "  'loss': 0.5218083958536578},\n",
       " 40: {'solver': 'sgd',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (2, 2),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.5948886252091758},\n",
       " 41: {'solver': 'sgd',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (3, 2),\n",
       "  'accuracy': 0.7324185248713551,\n",
       "  'loss': 0.5110095533623659},\n",
       " 42: {'solver': 'sgd',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (5, 2),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.5358956552392288},\n",
       " 43: {'solver': 'sgd',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (2,),\n",
       "  'accuracy': 0.7169811320754716,\n",
       "  'loss': 0.5437884754841127},\n",
       " 44: {'solver': 'sgd',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (3,),\n",
       "  'accuracy': 0.7084048027444254,\n",
       "  'loss': 0.5706992216855763},\n",
       " 45: {'solver': 'sgd',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (5,),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.5360453936760733},\n",
       " 46: {'solver': 'sgd',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (2, 2),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.5964588996813154},\n",
       " 47: {'solver': 'sgd',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (3, 2),\n",
       "  'accuracy': 0.7358490566037735,\n",
       "  'loss': 0.514650095872774},\n",
       " 48: {'solver': 'sgd',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (5, 2),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.6022581944579103},\n",
       " 49: {'solver': 'adam',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (2,),\n",
       "  'accuracy': 0.7204116638078902,\n",
       "  'loss': 0.5024579987607447},\n",
       " 50: {'solver': 'adam',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (3,),\n",
       "  'accuracy': 0.7238421955403087,\n",
       "  'loss': 0.5035647038455272},\n",
       " 51: {'solver': 'adam',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (5,),\n",
       "  'accuracy': 0.7272727272727273,\n",
       "  'loss': 0.4981853205040311},\n",
       " 52: {'solver': 'adam',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (2, 2),\n",
       "  'accuracy': 0.7238421955403087,\n",
       "  'loss': 0.5035551190229633},\n",
       " 53: {'solver': 'adam',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (3, 2),\n",
       "  'accuracy': 0.725557461406518,\n",
       "  'loss': 0.49560557910455055},\n",
       " 54: {'solver': 'adam',\n",
       "  'activation_function': 'identity',\n",
       "  'hidden_layers': (5, 2),\n",
       "  'accuracy': 0.7221269296740995,\n",
       "  'loss': 0.4993437516333602},\n",
       " 55: {'solver': 'adam',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (2,),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.5336543175704784},\n",
       " 56: {'solver': 'adam',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (3,),\n",
       "  'accuracy': 0.7169811320754716,\n",
       "  'loss': 0.5087031850321266},\n",
       " 57: {'solver': 'adam',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (5,),\n",
       "  'accuracy': 0.725557461406518,\n",
       "  'loss': 0.5002944274155354},\n",
       " 58: {'solver': 'adam',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (2, 2),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.5926078212209708},\n",
       " 59: {'solver': 'adam',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (3, 2),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.5213957058184708},\n",
       " 60: {'solver': 'adam',\n",
       "  'activation_function': 'logistic',\n",
       "  'hidden_layers': (5, 2),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.50292072925518},\n",
       " 61: {'solver': 'adam',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (2,),\n",
       "  'accuracy': 0.725557461406518,\n",
       "  'loss': 0.4978487445867842},\n",
       " 62: {'solver': 'adam',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (3,),\n",
       "  'accuracy': 0.7204116638078902,\n",
       "  'loss': 0.4981461339469674},\n",
       " 63: {'solver': 'adam',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (5,),\n",
       "  'accuracy': 0.7392795883361921,\n",
       "  'loss': 0.4913226851273854},\n",
       " 64: {'solver': 'adam',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (2, 2),\n",
       "  'accuracy': 0.7221269296740995,\n",
       "  'loss': 0.5004479093520382},\n",
       " 65: {'solver': 'adam',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (3, 2),\n",
       "  'accuracy': 0.7512864493996569,\n",
       "  'loss': 0.48671903452719817},\n",
       " 66: {'solver': 'adam',\n",
       "  'activation_function': 'tanh',\n",
       "  'hidden_layers': (5, 2),\n",
       "  'accuracy': 0.7358490566037735,\n",
       "  'loss': 0.49388042543065397},\n",
       " 67: {'solver': 'adam',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (2,),\n",
       "  'accuracy': 0.725557461406518,\n",
       "  'loss': 0.5263050170179094},\n",
       " 68: {'solver': 'adam',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (3,),\n",
       "  'accuracy': 0.725557461406518,\n",
       "  'loss': 0.4972970654610325},\n",
       " 69: {'solver': 'adam',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (5,),\n",
       "  'accuracy': 0.7392795883361921,\n",
       "  'loss': 0.4826902882850586},\n",
       " 70: {'solver': 'adam',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (2, 2),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.5133740026967538},\n",
       " 71: {'solver': 'adam',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (3, 2),\n",
       "  'accuracy': 0.7307032590051458,\n",
       "  'loss': 0.4892486685857735},\n",
       " 72: {'solver': 'adam',\n",
       "  'activation_function': 'relu',\n",
       "  'hidden_layers': (5, 2),\n",
       "  'accuracy': 0.7135506003430532,\n",
       "  'loss': 0.47815328611186053}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
